{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AUMENTO_Y_TFRECORDS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mapo-lp/mapo-lp.github.io/blob/master/AUMENTO_Y_TFRECORDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwxIcBsXuFW2"
      },
      "source": [
        "##Aumento de imagenes y generacion de tfrecords \n",
        "\n",
        "#####Input: imagenes y archivos .xml desde Github\n",
        "#####Output: tfrecods y label_map.pbtxt a Github"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYW_Tdi7V4Sf"
      },
      "source": [
        "####Params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRoJbJldUGuj"
      },
      "source": [
        "generate_images_count =  100#@param {type:\"integer\"}\n",
        "\n",
        "# mostrar imagenes originales y sus transformaciones, para debug\n",
        "show_generated_images = True #@param {type:\"boolean\"}\n",
        "images_to_show =  1#@param {type:\"integer\"}\n",
        "\n",
        "images_repo_url = 'https://github.com/mapo-lp/test' #@param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(images_repo_url)))\n",
        "path_annotations = repo_dir_path+'/annotations' \n",
        "path_images_train = repo_dir_path+'/images/train'\n",
        "path_images_test = repo_dir_path+'/images/test' \n",
        "\n",
        "github_pass = '' #@param {type:\"string\"}\n",
        "repo = 'https://mapo-lp:'+github_pass+'@github.com/mapo-lp/wally.git'\n",
        "github_mail = '' #@param {type:\"string\"}\n",
        "github_user = '' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeJEEzxTWCl-"
      },
      "source": [
        "####Clonamos repo con imagenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxIEIeWnaYYa"
      },
      "source": [
        "%cd /content\n",
        "!git clone {images_repo_url}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtU39QneWGd9"
      },
      "source": [
        "####Instalamos libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKRF6s9Xer-N"
      },
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "%tensorflow_version 1.x\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "from imgaug import augmenters as iaa \n",
        "import imageio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOkJ77C4kWwW"
      },
      "source": [
        "####Funciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g02Z6rO8czDt"
      },
      "source": [
        "# Function that will extract column data for our CSV file as pandas DataFrame\n",
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            value = (root.find('filename').text,\n",
        "                     int(root.find('size')[0].text),\n",
        "                     int(root.find('size')[1].text),\n",
        "                     member[0].text,\n",
        "                     int(member[4][0].text),\n",
        "                     int(member[4][1].text),\n",
        "                     int(member[4][2].text),\n",
        "                     int(member[4][3].text)\n",
        "                     )\n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df\n",
        "   \n",
        "# apply the function to convert all XML files in images/ folder into labels.csv\n",
        "if os.path.exists(path_annotations):\n",
        "  shutil.rmtree(path_annotations)\n",
        "\n",
        "os.mkdir(path_annotations) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwHIm9hhc1r7"
      },
      "source": [
        "# function to convert BoundingBoxesOnImage object into DataFrame\n",
        "def bbs_obj_to_df(bbs_object):\n",
        "#     convert BoundingBoxesOnImage object into array\n",
        "    bbs_array = bbs_object.to_xyxy_array()\n",
        "#     convert array into a DataFrame ['xmin', 'ymin', 'xmax', 'ymax'] columns\n",
        "    df_bbs = pd.DataFrame(bbs_array, columns=['xmin', 'ymin', 'xmax', 'ymax'])\n",
        "    return df_bbs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMioOaJ8Hf-A"
      },
      "source": [
        "def image_aug(df, images_path, aug_images_path, image_prefix, augmentor):\n",
        "    # create data frame which we're going to populate with augmented image info\n",
        "    aug_bbs_xy = pd.DataFrame(columns=\n",
        "                              ['filename','width','height','class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "                             )\n",
        "    grouped = df.groupby('filename')\n",
        "    \n",
        "    for filename in df['filename'].unique():\n",
        "    #   get separate data frame grouped by file name\n",
        "        group_df = grouped.get_group(filename)\n",
        "        group_df = group_df.reset_index()\n",
        "        group_df = group_df.drop(['index'], axis=1)   \n",
        "    #   read the image\n",
        "        image = imageio.imread(images_path+filename)\n",
        "    #   get bounding boxes coordinates and write into array        \n",
        "        bb_array = group_df.drop(['filename', 'width', 'height', 'class'], axis=1).values\n",
        "    #   pass the array of bounding boxes coordinates to the imgaug library\n",
        "        bbs = BoundingBoxesOnImage.from_xyxy_array(bb_array, shape=image.shape)\n",
        "    #   apply augmentation on image and on the bounding boxes\n",
        "        image_aug, bbs_aug = augmentor(image=image, bounding_boxes=bbs)\n",
        "    #   disregard bounding boxes which have fallen out of image pane    \n",
        "        bbs_aug = bbs_aug.remove_out_of_image()\n",
        "    #   clip bounding boxes which are partially outside of image pane\n",
        "        bbs_aug = bbs_aug.clip_out_of_image()\n",
        "        \n",
        "    #   don't perform any actions with the image if there are no bounding boxes left in it    \n",
        "        if re.findall('Image...', str(bbs_aug)) == ['Image([]']:\n",
        "            pass\n",
        "        \n",
        "    #   otherwise continue\n",
        "        else:\n",
        "        #   write augmented image to a file\n",
        "            imageio.imwrite(aug_images_path+image_prefix+filename, image_aug)  \n",
        "        #   create a data frame with augmented values of image width and height\n",
        "            info_df = group_df.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1)    \n",
        "            for index, _ in info_df.iterrows():\n",
        "                info_df.at[index, 'width'] = image_aug.shape[1]\n",
        "                info_df.at[index, 'height'] = image_aug.shape[0]\n",
        "        #   rename filenames by adding the predifined prefix\n",
        "            info_df['filename'] = info_df['filename'].apply(lambda x: image_prefix+x)\n",
        "        #   create a data frame with augmented bounding boxes coordinates using the function we created earlier\n",
        "            bbs_df = bbs_obj_to_df(bbs_aug)\n",
        "        #   concat all new augmented info into new data frame\n",
        "            aug_df = pd.concat([info_df, bbs_df], axis=1)\n",
        "        #   append rows to aug_bbs_xy data frame\n",
        "            aug_bbs_xy = pd.concat([aug_bbs_xy, aug_df])            \n",
        "    \n",
        "    # return dataframe with updated images and bounding boxes annotations \n",
        "    aug_bbs_xy = aug_bbs_xy.reset_index()\n",
        "    aug_bbs_xy = aug_bbs_xy.drop(['index'], axis=1)\n",
        "    return aug_bbs_xy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2ATZKCGFldV"
      },
      "source": [
        "train_labels_df = xml_to_csv(path_images_train)\n",
        "train_labels_df.to_csv((path_annotations+'/temp_train_labels.csv'), index=None)\n",
        "\n",
        "test_labels_df = xml_to_csv(path_images_test)\n",
        "test_labels_df.to_csv((path_annotations+'/temp_test_labels.csv'), index=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpvV_Jk-DTCM"
      },
      "source": [
        "las transformaciones son las de la libreria albumnations, que es un wrapper de imgaug .. las posibles opciones son las mencionadas en https://albumentations.readthedocs.io/en/latest/api/index.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDULYmHic86-"
      },
      "source": [
        "aug = iaa.SomeOf(4, [    \n",
        "    iaa.Affine(scale=(0.2, 1.5)),\n",
        "    iaa.Affine(rotate=(-120, 60)),\n",
        "    iaa.Affine(translate_percent={\"x\":(-0.8, 0.3),\"y\":(-0.3, 0.3)}),\n",
        "    iaa.Fliplr(1),\n",
        "    iaa.Add((-10, 10), per_channel=0.5),\n",
        "                    iaa.Multiply((0.75, 1.25), per_channel=0.5),\n",
        "                    iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5),\n",
        "                    iaa.Crop(px=(0, 20)),\n",
        "    iaa.GaussianBlur((0, 2.5)),\n",
        "    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01 * 255), per_channel=0.5),\n",
        "    iaa.AddToHueAndSaturation((-5, 8)),  # change hue and saturation\n",
        "    iaa.PiecewiseAffine(scale=(0.01, 0.03)),\n",
        "    iaa.PerspectiveTransform(scale=(0.01, 0.2))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab2pk5h5dCUW"
      },
      "source": [
        "if os.path.exists(path_images_train+'/aug_images'):\n",
        "  shutil.rmtree(path_images_train+'/aug_images')\n",
        "os.mkdir(path_images_train+'/aug_images') \n",
        "\n",
        "if os.path.exists(path_images_test+'/aug_images'):\n",
        "  shutil.rmtree(path_images_test+'/aug_images')\n",
        "os.mkdir(path_images_test+'/aug_images') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd_ftSrOHkZj"
      },
      "source": [
        "####Aumentamos imagenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uji4U6PqdFWo"
      },
      "source": [
        "# initialize empty DataFrame\n",
        "augmented_images_train_df = pd.DataFrame(columns=['filename','width','height','class','xmin','ymin','xmax','ymax'])\n",
        "# apply augmentation function 5 times to the same set of images\n",
        "for i in range(generate_images_count):\n",
        "    aug_df = image_aug(train_labels_df, path_images_train+'/', path_images_train+'/aug_images/', 'aug'+str(i)+'_', aug)\n",
        "    augmented_images_train_df = pd.concat([augmented_images_train_df, aug_df])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO9wBpVteqPh"
      },
      "source": [
        "if show_generated_images:\n",
        "  %matplotlib inline\n",
        "  import matplotlib as mpl\n",
        "  import matplotlib.pyplot as plt\n",
        "  import PIL.ImageDraw as ImageDraw\n",
        "  IMAGE_SIZE = (12, 8)\n",
        "\n",
        "  i = 0\n",
        "\n",
        "  for filename in train_labels_df['filename'].unique():\n",
        "    \n",
        "    if i == images_to_show:\n",
        "      break;\n",
        "\n",
        "    asd = augmented_images_train_df[augmented_images_train_df[\"filename\"].str.contains(filename)]\n",
        "    \n",
        "    for filename1 in asd['filename'].unique():\n",
        "      grouped = asd.groupby('filename')\n",
        "      group_df = grouped.get_group(filename1)\n",
        "    \n",
        "      plt.figure(figsize=IMAGE_SIZE)\n",
        "      image = imageio.imread(path_images_train+'/aug_images/'+filename1)\n",
        "      plt.imshow(image)\n",
        "\n",
        "      for index, row in group_df.iterrows():\n",
        "          coord = [[row['xmin'], row['ymax']], [row['xmax'], row['ymax']], [row['xmax'], row['ymin']], [row['xmin'], row['ymin']]]\n",
        "          coord.append(coord[0]) #repeat the first point to create a 'closed loop'\n",
        "          coord.append(coord[1])\n",
        "          coord.append(coord[2])\n",
        "          coord.append(coord[3])\n",
        "          xs, ys = zip(*coord) #create lists of x and y values\n",
        "          plt.plot(xs,ys, linewidth=4) \n",
        "    \n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdXRbQCJZ-mb"
      },
      "source": [
        "# initialize empty DataFrame\n",
        "augmented_images_test_df = pd.DataFrame(columns=['filename','width','height','class','xmin','ymin','xmax','ymax'])\n",
        "# apply augmentation function 5 times to the same set of images\n",
        "for i in range(int(generate_images_count)):\n",
        "    aug_df = image_aug(test_labels_df, path_images_test+'/', path_images_test+'/aug_images/', 'aug'+str(i)+'_', aug)\n",
        "    augmented_images_test_df = pd.concat([augmented_images_test_df, aug_df])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF48bKZPdIcN"
      },
      "source": [
        "all_labels_train_df = pd.concat([train_labels_df, augmented_images_train_df])\n",
        "all_labels_train_df.to_csv(path_annotations+'/train_labels.csv', index=False)\n",
        "\n",
        "all_labels_test_df = pd.concat([test_labels_df, augmented_images_test_df])\n",
        "all_labels_test_df.to_csv(path_annotations+'/test_labels.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ftz_tVKdJzg"
      },
      "source": [
        "for file in os.listdir(path_images_train+'/aug_images/'):\n",
        "    shutil.copy(path_images_train+'/aug_images/'+file, path_images_train+'/'+file)\n",
        "\n",
        "for file in os.listdir(path_images_test+'/aug_images/'):\n",
        "    shutil.copy(path_images_test+'/aug_images/'+file, path_images_test+'/'+file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5pVpxzqk1vz"
      },
      "source": [
        "####Generamos train.record, test.record y label_map.pbtxt a partir de los .csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVVU8uoLdap8"
      },
      "source": [
        "%cd {repo_dir_path}\n",
        "\n",
        "# Convert train folder annotation xml files to a single csv file,\n",
        "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
        "!python code/xml_to_csv.py -i images/train -o annotations/trainn_labels.csv -l annotations\n",
        "\n",
        "# Generate `train.record`\n",
        "!python code/generate_tfrecord.py --csv_input=annotations/train_labels.csv --output_path=annotations/train.record --img_path=images/train --label_map annotations/label_map.pbtxt\n",
        "\n",
        "# Generate `test.record`\n",
        "!python code/generate_tfrecord.py --csv_input=annotations/test_labels.csv --output_path=annotations/test.record --img_path=images/test --label_map annotations/label_map.pbtxt\n",
        "\n",
        "# clear resources\n",
        "!rm '{path_annotations}/temp_train_labels.csv'\n",
        "!rm '{path_annotations}/temp_test_labels.csv'\n",
        "\n",
        "if os.path.exists(path_images_train+'/aug_images'):\n",
        "  shutil.rmtree(path_images_train+'/aug_images')\n",
        "\n",
        "if os.path.exists(path_images_test+'/aug_images'):\n",
        "  shutil.rmtree(path_images_test+'/aug_images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_bZR1Kbk69Q"
      },
      "source": [
        "####Subimos esos archivos a Github."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fH5T7vXhfzqH"
      },
      "source": [
        "%cd {repo_dir_path}\n",
        "!git remote rm origin\n",
        "!git init\n",
        "!git remote add origin {repo}\n",
        "!git config --global user.email {github_mail}\n",
        "!git config --global user.name {github_user}\n",
        "\n",
        "%cd {path_annotations}\n",
        "!git add test.record\n",
        "!git add train.record\n",
        "!git add label_map.pbtxt\n",
        "!git commit -m 'tfrecords actualizados' \n",
        "!git push -u origin main          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUcKc2H2HN_k"
      },
      "source": [
        "###Listo."
      ]
    }
  ]
}